{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Tuple, Callable, Dict, Optional, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sps\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    return pd.read_csv(\"./data/data_train.csv\",\n",
    "                      sep=\",\",\n",
    "                      names=[\"user_id\",\"item_id\",\"impl_rating\"],\n",
    "                      header=None,\n",
    "                      skiprows=1,\n",
    "                      dtype={\"user_id\": np.int32,\n",
    "                             \"item_id\": np.int32,\n",
    "                             \"impl_rating\": np.int32})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "impl_ratings = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>impl_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10080</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>19467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2665</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7494</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>17068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113263</th>\n",
       "      <td>7945</td>\n",
       "      <td>2476</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113264</th>\n",
       "      <td>7945</td>\n",
       "      <td>12319</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113265</th>\n",
       "      <td>7945</td>\n",
       "      <td>21384</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113266</th>\n",
       "      <td>7946</td>\n",
       "      <td>8699</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113267</th>\n",
       "      <td>7946</td>\n",
       "      <td>19178</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113268 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  item_id  impl_rating\n",
       "0             0    10080            1\n",
       "1             0    19467            1\n",
       "2             1     2665            1\n",
       "3             1     7494            1\n",
       "4             1    17068            1\n",
       "...         ...      ...          ...\n",
       "113263     7945     2476            1\n",
       "113264     7945    12319            1\n",
       "113265     7945    21384            1\n",
       "113266     7946     8699            1\n",
       "113267     7946    19178            1\n",
       "\n",
       "[113268 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impl_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(ratings: pd.DataFrame):\n",
    "    unique_users = impl_ratings.user_id.unique()\n",
    "    unique_items = impl_ratings.item_id.unique()\n",
    "    \n",
    "    num_users, min_user_id, max_user_id = unique_users.size, unique_users.min(), unique_users.max()\n",
    "    num_items, min_item_id, max_item_id = unique_items.size, unique_items.min(), unique_items.max()\n",
    "    \n",
    "    print(num_users, min_user_id, max_user_id)\n",
    "    print(num_items, min_item_id, max_item_id)\n",
    "    \n",
    "    mapping_user_id = pd.DataFrame({\"mapped_user_id\": np.arange(num_users), \"user_id\": unique_users})\n",
    "    mapping_item_id = pd.DataFrame({\"mapped_item_id\": np.arange(num_items), \"item_id\": unique_items})\n",
    "    \n",
    "    ratings = pd.merge(left=ratings,\n",
    "                      right=mapping_user_id,\n",
    "                      how=\"inner\",\n",
    "                      on=\"user_id\")\n",
    "    \n",
    "    ratings = pd.merge(left=ratings,\n",
    "                      right=mapping_item_id,\n",
    "                      how=\"inner\",\n",
    "                      on=\"item_id\")\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7947 0 7946\n",
      "24896 0 25974\n"
     ]
    }
   ],
   "source": [
    "ratings = preprocess_data(impl_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>impl_rating</th>\n",
       "      <th>mapped_user_id</th>\n",
       "      <th>mapped_item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10080</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4342</td>\n",
       "      <td>10080</td>\n",
       "      <td>1</td>\n",
       "      <td>4342</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5526</td>\n",
       "      <td>10080</td>\n",
       "      <td>1</td>\n",
       "      <td>5526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5923</td>\n",
       "      <td>10080</td>\n",
       "      <td>1</td>\n",
       "      <td>5923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>19467</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113263</th>\n",
       "      <td>7944</td>\n",
       "      <td>22542</td>\n",
       "      <td>1</td>\n",
       "      <td>7944</td>\n",
       "      <td>24891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113264</th>\n",
       "      <td>7944</td>\n",
       "      <td>24806</td>\n",
       "      <td>1</td>\n",
       "      <td>7944</td>\n",
       "      <td>24892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113265</th>\n",
       "      <td>7944</td>\n",
       "      <td>24912</td>\n",
       "      <td>1</td>\n",
       "      <td>7944</td>\n",
       "      <td>24893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113266</th>\n",
       "      <td>7944</td>\n",
       "      <td>24990</td>\n",
       "      <td>1</td>\n",
       "      <td>7944</td>\n",
       "      <td>24894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113267</th>\n",
       "      <td>7944</td>\n",
       "      <td>25953</td>\n",
       "      <td>1</td>\n",
       "      <td>7944</td>\n",
       "      <td>24895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113268 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  item_id  impl_rating  mapped_user_id  mapped_item_id\n",
       "0             0    10080            1               0               0\n",
       "1          4342    10080            1            4342               0\n",
       "2          5526    10080            1            5526               0\n",
       "3          5923    10080            1            5923               0\n",
       "4             0    19467            1               0               1\n",
       "...         ...      ...          ...             ...             ...\n",
       "113263     7944    22542            1            7944           24891\n",
       "113264     7944    24806            1            7944           24892\n",
       "113265     7944    24912            1            7944           24893\n",
       "113266     7944    24990            1            7944           24894\n",
       "113267     7944    25953            1            7944           24895\n",
       "\n",
       "[113268 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_splits(ratings,num_users,num_items, val_perc: float, test_perc: float):\n",
    "    seed=9876\n",
    "    \n",
    "    (uid_training, uid_test,\n",
    "    iid_training, iid_test,\n",
    "    ratings_training, ratings_test) = train_test_split(ratings.mapped_user_id,\n",
    "                                                      ratings.mapped_item_id,\n",
    "                                                      ratings.impl_rating,\n",
    "                                                      test_size=test_perc,\n",
    "                                                      shuffle=True,\n",
    "                                                      random_state=seed)\n",
    "    (uid_training, uid_validation,\n",
    "    iid_training, iid_validation,\n",
    "    ratings_training, ratings_validation) = train_test_split(uid_training,\n",
    "                                                            iid_training,\n",
    "                                                            ratings_training,\n",
    "                                                            test_size=val_perc)\n",
    "    \n",
    "    urm_train = sps.csr_matrix((ratings_training,(uid_training,iid_training)), shape=(num_users,num_items))\n",
    "    urm_val = sps.csr_matrix((ratings_validation,(uid_validation,iid_validation)), shape=(num_users,num_items))\n",
    "    urm_test = sps.csr_matrix((ratings_test,(uid_test,iid_test)), shape=(num_users,num_items))\n",
    "    \n",
    "    return urm_train,urm_val,urm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "urm_train,urm_val,urm_test = dataset_splits(ratings, \n",
    "                                            num_users=7947, \n",
    "                                            num_items=24896, \n",
    "                                            val_perc=0.1, \n",
    "                                            test_perc=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7947x24896 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 81552 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7947x24896 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 9062 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urm_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7947x24896 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 22654 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urm_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Function for similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(urm: sps.csc_matrix, shrink: int):\n",
    "    item_weights = np.sqrt(\n",
    "                        np.sum(\n",
    "                        urm_train.tocsc().power(2),\n",
    "                        axis=0\n",
    "                        )\n",
    "                   ).A.flatten()\n",
    "    \n",
    "    num_items = urm.shape[1]\n",
    "    item_dot_product = urm.T.dot(urm).todense()\n",
    "    \n",
    "    weights = np.empty(shape=(num_items, num_items))\n",
    "    for item_id in range(num_items):\n",
    "        numerator = item_dot_product[item_id]\n",
    "        denominator = item_weights[item_id]* item_weights + shrink + 1e-6 \n",
    "        \n",
    "        weights[item_id] = numerator / denominator\n",
    "        \n",
    "    np.fill_diagonal(weights, 0.0)\n",
    "    \n",
    "    return weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "weights = similarity(urm_train.tocsc(), shrink=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity\n",
    "\n",
    "We can implement different versions of a cosine similarity. Some of these are faster and others are slower.\n",
    "\n",
    "The most simple version is just to loop item by item and calculate the similarity of item pairs.\n",
    "$$ W_{i,j} \n",
    "= cos(v_i, v_j) \n",
    "= \\frac{v_i \\cdot v_j}{|| v_i || ||v_j ||} \n",
    "= \\frac{\\Sigma_{u \\in U}{URM_{u,i} \\cdot URM_{u,j}}}{\\sqrt{\\Sigma_{u \\in U}{URM_{u,i}^2}} \\cdot \\sqrt{\\Sigma_{u \\in U}{URM_{u,j}^2}} + shrink} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_similarity(urm: sps.csc_matrix, shrink: int):\n",
    "    num_items = urm.shape[1]\n",
    "    weights = np.empty(shape=(num_items, num_items))\n",
    "    for item_i in range(num_items):\n",
    "        item_i_profile = urm[:, item_i] # mx1 vector\n",
    "        \n",
    "        for item_j in range(num_items):\n",
    "            item_j_profile = urm[:, item_j] # mx1 vector\n",
    "                      \n",
    "            numerator = item_i_profile.T.dot(item_j_profile).todense()[0,0]\n",
    "            denominator = (np.sqrt(np.sum(item_i_profile.power(2)))\n",
    "                           * np.sqrt(np.sum(item_j_profile.power(2)))\n",
    "                           + shrink\n",
    "                           + 1e-6)\n",
    "            \n",
    "            weights[item_i, item_j] = numerator / denominator\n",
    "    \n",
    "    np.fill_diagonal(weights, 0.0)\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another (faster) version of the similarity is by operating on vector products\n",
    "$$ W_{i,I} \n",
    "= cos(v_i, URM_{I}) \n",
    "= \\frac{v_i \\cdot URM_{I}}{|| v_i || IW_{I} + shrink} $$\n",
    "\n",
    "and where \n",
    "\n",
    "$$ IW_{i} = \\sqrt{{\\Sigma_{u \\in U}{URM_{u,i}^2}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_similarity(urm: sps.csc_matrix, shrink: int):\n",
    "    item_weights = np.sqrt(\n",
    "        np.sum(urm.power(2), axis=0)\n",
    "    ).A.flatten()\n",
    "    \n",
    "    num_items = urm.shape[1]\n",
    "    urm_t = urm.T\n",
    "    weights = np.empty(shape=(num_items, num_items))\n",
    "    for item_id in range(num_items):\n",
    "        numerator = urm_t.dot(urm[:, item_id]).A.flatten()\n",
    "        denominator = item_weights[item_id] * item_weights + shrink + 1e-6\n",
    "        \n",
    "        weights[item_id] = numerator / denominator\n",
    "        \n",
    "    np.fill_diagonal(weights, 0.0)\n",
    "    return weights\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, a faster but more memory-intensive version of the similarity is by operating on matrix products\n",
    "$$ W  \n",
    "= \\frac{URM^{t} \\cdot URM}{IW^{t} IW + shrink} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_similarity(urm: sps.csc_matrix, shrink: int):\n",
    "    item_weights = np.sqrt(\n",
    "        np.sum(urm.power(2), axis=0)\n",
    "    ).A\n",
    "    \n",
    "    numerator = urm.T.dot(urm)\n",
    "    denominator = item_weights.T.dot(item_weights) + shrink + 1e-6\n",
    "    weights = numerator / denominator\n",
    "    np.fill_diagonal(weights, 0.0)\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "urm_csc = urm_train.tocsc()\n",
    "shrink = 5\n",
    "slice_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.16666664, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.16666664, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.16666664,\n",
       "        0.16666664],\n",
       "       [0.        , 0.        , 0.        , ..., 0.16666664, 0.        ,\n",
       "        0.16666664],\n",
       "       [0.        , 0.        , 0.        , ..., 0.16666664, 0.16666664,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "naive_weights = naive_similarity(urm_csc[:slice_size,:slice_size], shrink)\n",
    "naive_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 35.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.16666664, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.16666664, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.16666664,\n",
       "        0.16666664],\n",
       "       [0.        , 0.        , 0.        , ..., 0.16666664, 0.        ,\n",
       "        0.16666664],\n",
       "       [0.        , 0.        , 0.        , ..., 0.16666664, 0.16666664,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "vector_weights = vector_similarity(urm_csc[:slice_size,:slice_size], shrink)\n",
    "vector_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.16666664, 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.16666664, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.16666664,\n",
       "         0.16666664],\n",
       "        [0.        , 0.        , 0.        , ..., 0.16666664, 0.        ,\n",
       "         0.16666664],\n",
       "        [0.        , 0.        , 0.        , ..., 0.16666664, 0.16666664,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "matrix_weights = matrix_similarity(urm_csc[:slice_size,:slice_size], shrink)\n",
    "matrix_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(naive_weights, vector_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(vector_weights, matrix_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Filtering ItemKNN Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFItemKNN(object):\n",
    "    \n",
    "    def __init__(self, shrink:int):\n",
    "        self.shrink = shrink\n",
    "        self.weights = None\n",
    "            \n",
    "    \n",
    "    def fit(self,urm_train: sps.csc_matrix, similarity_func: Callable[[sps.csc_matrix, int], np.array]):\n",
    "        if not sps.isspmatrix_csc(urm_train):\n",
    "            raise TypeError(f\"We expected a CSC matrix, we got {type(urm_train)}\")\n",
    "        \n",
    "        self.weights = similarity_func(urm_train, self.shrink)\n",
    "        \n",
    "    def recommend(self, user_id: int, urm_train: sps.csr_matrix, at: Optional[int] = None, remove_unseen: bool = True):\n",
    "        user_profile = urm_train[user_id]\n",
    "        \n",
    "        ranking = user_profile.dot(self.weights).A.flatten()\n",
    "        \n",
    "        if remove_unseen:\n",
    "            user_profile_start = urm_train.indptr[user_id]\n",
    "            user_profile_end = urm_train.indptr[user_id+1]\n",
    "            \n",
    "            seen_items = urm_train.indices[user_profile_start:user_profile_end]\n",
    "            \n",
    "            ranking[seen_items] = -np.inf\n",
    "            \n",
    "        ranking = np.argsort(-ranking)\n",
    "        return ranking[:at]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemknn_recommender = CFItemKNN(shrink=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "itemknn_recommender.fit(urm_train.tocsc(),matrix_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1836 23196  1849  8104  3021  6319  2002  1707  9769  2896]\n",
      "[1066 1704  133 1065 1526 1105 1460 2126 2627 2930]\n",
      "[    0 16603 16602 16601 16600 16599 16598 16597 16596 16595]\n",
      "[14995  2178  4589 23335 23336 10292 21660 21925 21924 15499]\n",
      "[ 245 1642 1971 6855 2841 3115 1015 9825 3154 2280]\n",
      "[ 1912  5434     3   329  1065   186  1460   644 13390  2800]\n",
      "[ 6294  1609  3476  1606  3498  3420  1424  1395 12479  3470]\n",
      "[   54  1369  9473 11641 11644  2789  7405  1996  1788   354]\n",
      "[3041 6268 2083  303 1827  551  644  304  186 1492]\n",
      "[3153 5105 1718 9815 2026 1066 2122 2134  489  445]\n"
     ]
    }
   ],
   "source": [
    "for user_id in range(10):\n",
    "    print(itemknn_recommender.recommend(user_id=user_id,\n",
    "                                  at=10, \n",
    "                                  urm_train=urm_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(recommendations: np.array, relevant_items: np.array) -> float:\n",
    "    is_relevant = np.in1d(recommendations, relevant_items, assume_unique=True)\n",
    "    \n",
    "    recall_score = np.sum(is_relevant) / relevant_items.shape[0]\n",
    "    \n",
    "    return recall_score\n",
    "    \n",
    "    \n",
    "def precision(recommendations: np.array, relevant_items: np.array) -> float:\n",
    "    is_relevant = np.in1d(recommendations, relevant_items, assume_unique=True)\n",
    "    \n",
    "    precision_score = np.sum(is_relevant) / recommendations.shape[0]\n",
    "\n",
    "    return precision_score\n",
    "\n",
    "def mean_average_precision(recommendations: np.array, relevant_items: np.array) -> float:\n",
    "    is_relevant = np.in1d(recommendations, relevant_items, assume_unique=True)\n",
    "    \n",
    "    precision_at_k = is_relevant * np.cumsum(is_relevant, dtype=np.float32) / (1 + np.arange(is_relevant.shape[0]))\n",
    "\n",
    "    map_score = np.sum(precision_at_k) / np.min([relevant_items.shape[0], is_relevant.shape[0]])\n",
    "\n",
    "    return map_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator(recommender: object, urm_train: sps.csr_matrix, urm_test: sps.csr_matrix):\n",
    "    recommendation_length = 10\n",
    "    accum_precision = 0\n",
    "    accum_recall = 0\n",
    "    accum_map = 0\n",
    "    \n",
    "    num_users = urm_train.shape[0]\n",
    "    \n",
    "    num_users_evaluated = 0\n",
    "    num_users_skipped = 0\n",
    "    \n",
    "    for user_id in range(num_users):\n",
    "        user_profile_start = urm_test.indptr[user_id]\n",
    "        user_profile_end = urm_test.indptr[user_id+1]\n",
    "        \n",
    "        relevant_items = urm_test.indices[user_profile_start:user_profile_end]\n",
    "        if relevant_items.size == 0:\n",
    "            num_users_skipped += 1\n",
    "            continue\n",
    "        \n",
    "        recommendations = recommender.recommend(user_id=user_id,\n",
    "                                               at=recommendation_length,\n",
    "                                               urm_train=urm_train)\n",
    "        \n",
    "        accum_precision += precision(recommendations, relevant_items)\n",
    "        accum_recall += recall(recommendations, relevant_items)\n",
    "        accum_map += mean_average_precision(recommendations, relevant_items)\n",
    "        \n",
    "        num_users_evaluated += 1\n",
    "        \n",
    "    accum_precision /= max(num_users_evaluated,1)\n",
    "    accum_recall /= max(num_users_evaluated,1) \n",
    "    accum_map /= max(num_users_evaluated,1)\n",
    "        \n",
    "    return accum_precision, accum_recall, accum_map, num_users_evaluated, num_users_skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "accum_precision, accum_recall, accum_map, num_user_evaluated, num_users_skipped = evaluator(itemknn_recommender,\n",
    "                                                                                            urm_train,\n",
    "                                                                                            urm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.027064712191633433, 0.08781670101760261, 0.04267728300883501, 5594, 2353)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accum_precision, accum_recall, accum_map, num_user_evaluated, num_users_skipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning():\n",
    "    shrinks = [0,1,5,10,50]\n",
    "    results = []\n",
    "    for shrink in shrinks:\n",
    "        print(f\"Currently trying shrink {shrink}\")\n",
    "        itemknn_recommender = CFItemKNN(shrink=shrink)\n",
    "        itemknn_recommender.fit(urm_train.tocsc(), matrix_similarity)\n",
    "        \n",
    "        ev_precision, ev_recall, ev_map,_,_ = evaluator(itemknn_recommender, urm_train, urm_val)\n",
    "        \n",
    "        results.append((shrink,(ev_precision, ev_recall, ev_map)))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently trying shrink 0\n",
      "Currently trying shrink 1\n",
      "Currently trying shrink 5\n",
      "Currently trying shrink 10\n",
      "Currently trying shrink 50\n",
      "Wall time: 6min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hyperparameter_results = hyperparameter_tuning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, (0.009231619679380916, 0.04789152139130158, 0.01960429709115185)),\n",
       " (1, (0.011138750690989562, 0.05763867150723729, 0.02285195168756034)),\n",
       " (5, (0.014980652294085246, 0.07551376594926669, 0.03134376992100608)),\n",
       " (10, (0.016362631288004553, 0.08084851985232039, 0.03512755976876345)),\n",
       " (50, (0.016832504145937108, 0.08456855483114999, 0.036860233864341986))]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameter_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission to competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_shrink = 50\n",
    "urm_train_validation = urm_train + urm_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_recommender = CFItemKNN(shrink=best_shrink)\n",
    "best_recommender.fit(urm_train_validation.tocsc(), matrix_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User to recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7939</th>\n",
       "      <td>7942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7940</th>\n",
       "      <td>7943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7941</th>\n",
       "      <td>7944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7942</th>\n",
       "      <td>7945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7943</th>\n",
       "      <td>7946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7944 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id\n",
       "0           0\n",
       "1           1\n",
       "2           2\n",
       "3           3\n",
       "4           4\n",
       "...       ...\n",
       "7939     7942\n",
       "7940     7943\n",
       "7941     7944\n",
       "7942     7945\n",
       "7943     7946\n",
       "\n",
       "[7944 rows x 1 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_to_recommend = pd.read_csv(\"./data/data_target_users_test.csv\",\n",
    "                      names=[\"user_id\"],\n",
    "                      header=None,\n",
    "                      skiprows=1,\n",
    "                      dtype={\"user_id\": np.int32})\n",
    "users_to_recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_submission(ratings: pd.DataFrame, users_to_recommend: np.array, urm_train: sps.csr_matrix, recommender: object):\n",
    "    user_ids_and_mappings = ratings[ratings.user_id.isin(users_to_recommend)][[\"user_id\", \"mapped_user_id\"]].drop_duplicates().sort_values(by=['user_id'])\n",
    "    \n",
    "    mapping_to_item_id = dict(zip(ratings.mapped_item_id, ratings.item_id))\n",
    "    \n",
    "    recommendation_length = 10\n",
    "    submission = []\n",
    "    for idx, row in user_ids_and_mappings.iterrows():\n",
    "        user_id = row.user_id\n",
    "        mapped_user_id = row.mapped_user_id\n",
    "        \n",
    "        recommendations = recommender.recommend(user_id= mapped_user_id,\n",
    "                                                urm_train=urm_train,\n",
    "                                                at=recommendation_length)\n",
    "        \n",
    "        submission.append((user_id, [mapping_to_item_id[item_id] for item_id in recommendations]))\n",
    "    \n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = prepare_submission(ratings, users_to_recommend.user_id, urm_train_validation, best_recommender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submission(submission, namefile: str):\n",
    "    with open(\"./submissions/\"+namefile+\".csv\", \"w\") as f:\n",
    "        f.write(\"user_id,item_list\\n\")\n",
    "        for user_id, items in submission:\n",
    "            f.write(f\"{user_id},{' '.join([str(item) for item in items])}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = date.today().strftime(\"%d-%m-%y\")\n",
    "write_submission(submission, today)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
